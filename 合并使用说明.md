# 📦 多区域扫描数据合并工具

## 🎯 功能说明

当你在 Minecraft 服务器不同区域多次扫描时，可以使用此工具合并所有数据并自动去重。

---

## 🚀 使用方法

### **方式 1：自动合并（推荐）**

#### 步骤：

1. **扫描不同区域，得到多个 JSON 文件**
   ```
   区域1扫描 → JSON_area1.json
   区域2扫描 → JSON_area2.json
   区域3扫描 → JSON_area3.json
   ```

2. **分别转换每个区域的数据**
   ```bash
   # 转换区域1
   python json_to_data.py JSON_area1.json data1.json
   
   # 转换区域2
   python json_to_data.py JSON_area2.json data2.json
   
   # 转换区域3
   python json_to_data.py JSON_area3.json data3.json
   ```

3. **把所有 data*.json 文件放在同一目录下**
   ```
   findjiage/
   ├── data1.json    ← 区域1
   ├── data2.json    ← 区域2
   ├── data3.json    ← 区域3
   └── merge_data.py
   ```

4. **运行合并脚本**
   ```bash
   python merge_data.py
   ```

5. **完成！** 会生成 `data.json` 文件（已去重）

---

### **方式 2：手动指定文件**

编辑 `merge_data.py` 文件，找到最后一行附近：

```python
# 方式2：手动指定文件（取消下面的注释）
merge_json_files(['data1.json', 'data2.json', 'data3.json'], 'data.json')
```

取消注释并修改文件名，然后运行：
```bash
python merge_data.py
```

---

## 🔍 去重规则

脚本会根据以下信息判断是否为重复记录：
- **位置坐标** (x, y, z)
- **玩家名**
- **物品名**

如果这三个信息完全相同，则认为是同一个商店的同一个商品，只保留一条。

**示例：**
```
❌ 重复（会被去掉）
  玩家: Jensen2022_
  物品: 钻石
  位置: 100, 64, 200
  价格: $50

✅ 保留
  玩家: Jensen2022_
  物品: 钻石
  位置: 100, 64, 200
  价格: $50
```

---

## 📊 输出示例

运行后会看到：

```
============================================================
📦 开始合并 JSON 文件...
============================================================
✅ 已加载: data1.json (456 条记录)
✅ 已加载: data2.json (512 条记录)
✅ 已加载: data3.json (388 条记录)

📊 总共加载: 1356 条记录
🔄 开始去重...
✅ 去重完成！
   - 原始记录: 1356
   - 重复记录: 45
   - 唯一记录: 1311

💾 合并结果已保存: data.json

============================================================
📈 合并后统计信息:
============================================================
   - 总交易数: 1311
   - 独立玩家: 208
   - 物品种类: 521
   - 最高价格: $9,999,999.00
   - 最低价格: $0.10
   - 平均价格: $1,234.56
============================================================
✨ 合并完成！
============================================================
```

---

## ⚙️ 高级设置

### 修改去重策略

打开 `merge_data.py`，找到这段代码（约第 70 行）：

```python
# 如果已存在，跳过（保留第一条）
if key not in unique_records:
    unique_records[key] = record

# 保留最新的（如果想这样的话）：
# unique_records[key] = record  # 总是覆盖
```

**选项 1**（默认）：保留第一次扫描到的
- 适合：稳定市场，价格不常变

**选项 2**：保留最后一次扫描到的
- 适合：价格经常变动
- 注释掉 `if` 语句，取消注释 `unique_records[key] = record`

---

## 🔄 完整工作流程

```
第一次扫描（中心区域）
   ↓
JSON_center.json
   ↓
python json_to_data.py JSON_center.json data_center.json
   ↓
上传到网站（初版上线）

─────────────────────────────────────

第二次扫描（北部区域）
   ↓
JSON_north.json
   ↓
python json_to_data.py JSON_north.json data_north.json
   ↓
合并: python merge_data.py
   ↓
上传新的 data.json（自动包含两个区域）

─────────────────────────────────────

第三次扫描（南部区域）
   ↓
JSON_south.json
   ↓
python json_to_data.py JSON_south.json data_south.json
   ↓
合并: python merge_data.py
   ↓
上传新的 data.json（自动包含三个区域）
```

---

## ⏰ 更新时间说明

合并后的 `data.json` 会自动使用**最新扫描的时间**作为更新时间。

例如：
- `data1.json` 扫描时间: 2025-11-04 10:00:00
- `data2.json` 扫描时间: 2025-11-04 15:30:00
- `data3.json` 扫描时间: 2025-11-04 14:00:00

合并后显示: **2025-11-04 15:30:00** （最新的）

---

## 💡 小贴士

1. **建议命名规范**
   ```
   data_center.json   ← 中心区域
   data_north.json    ← 北部
   data_south.json    ← 南部
   data_east.json     ← 东部
   data_west.json     ← 西部
   ```

2. **增量更新**
   - 不需要每次都重新扫描所有区域
   - 只更新变化的区域，重新合并即可

3. **备份**
   - 合并前建议备份原文件
   - 或使用不同的输出文件名

4. **验证**
   - 合并后在本地测试 `http://localhost:8000`
   - 确认数据正确后再上传到虚拟主机

---

## ❓ 常见问题

### Q: 合并后数据变少了？
A: 这是正常的去重效果。重复的商店/物品被合并了。

### Q: 可以合并超过3个文件吗？
A: 可以！支持任意数量的文件。

### Q: 如何查看哪些是重复的？
A: 看输出信息中的"重复记录"数量。

### Q: 合并会不会丢失数据？
A: 不会。相同位置的同一物品只保留一条，但不同物品都会保留。

---

## 🎯 实战示例

假设你服务器有个大型市场，分4个区域：

```bash
# 扫描A区
/scan area_a
# 保存为 JSON_a.json

# 扫描B区
/scan area_b  
# 保存为 JSON_b.json

# 扫描C区
/scan area_c
# 保存为 JSON_c.json

# 扫描D区
/scan area_d
# 保存为 JSON_d.json

# 批量转换
python json_to_data.py JSON_a.json data_a.json
python json_to_data.py JSON_b.json data_b.json
python json_to_data.py JSON_c.json data_c.json
python json_to_data.py JSON_d.json data_d.json

# 一键合并
python merge_data.py

# 完成！data.json 包含所有4个区域的数据
```

---

**享受完整的市场数据吧！** 🎉

